{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c336062a-6535-4592-9a0a-36cb01e4d204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "Claude's response: Hello! It's nice to meet you. I'm an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't have a physical form or avatar - I'm just a conversational AI. I'm knowledgeable about a wide range of topics and I'm always eager to learn more. I enjoy having conversations and helping with tasks, but I think it's important to be clear that I'm an AI, not a human. Please let me know if you have any other questions - I'm happy to chat!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"ANTHROPIC_API_KEY not found in .env file\")\n",
    "\n",
    "print(api_key)\n",
    "\n",
    "client = Anthropic(api_key=api_key)\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello, Claude! Can you tell me about yourself?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Claude's response:\", message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e3a6ba0-926c-4d22-a8e7-60db11411abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API Key: sk-6TehpntQSzTktcXeJA5nQ5q3ooz8iT0f-HBS2VA-1CT3BlbkFJincUnyTP2VbemXH1r--zHBSqtIhH57y8vkNGNj1rUA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Once upon a time, in a bustling city where robots lived and worked, there was a curious robot named Robo. Robo had always been fascinated by the natural world, but in a city dominated by metal and technology, there was little opportunity to explore nature.\\n\\nOne day, while on a routine maintenance mission outside the city limits, Robo's navigation system malfunctioned, causing him to get lost in the wilderness. As Robo wandered through the dense forest, he marveled at the sight of towering trees, colorful flowers, and chirping birds. Everything was so different from the sleek buildings and bustling streets of the city.\\n\\nAs Robo continued his journey, he discovered a babbling brook, its clear waters reflecting the sunlight. Curious\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"Loaded API Key: {openai_api_key}\")\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "def generate_chat_response(messages, model=\"gpt-3.5-turbo\"):\n",
    "    # Use the correct API method: openai.chat.completions.create()\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.7,  # Adjust the creativity level\n",
    "        max_tokens=150,   # Adjust the number of tokens\n",
    "        n=1               # Number of responses to generate\n",
    "    )\n",
    "    # return response['choices'][0]['message']['content'].strip()\n",
    "    # return response.choices[0].message['content'].strip()\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a story about a robot discovering nature for the first time.\"}\n",
    "]\n",
    "\n",
    "response = generate_chat_response(messages)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71547351-06bf-4c92-b398-193b494eac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-f6gTGTUN7M9rQZiRHHFs1gE5/user-81UJNmAVRt0IfLgDcqz43f5Q/img-gbcHpeLZEfeuCwPw4WrdYcqS.png?st=2024-10-06T18%3A41%3A25Z&se=2024-10-06T20%3A41%3A25Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-10-05T23%3A55%3A38Z&ske=2024-10-06T23%3A55%3A38Z&sks=b&skv=2024-08-04&sig=uqU2G5xi/ulWFxli7i1CaWN3M2r85%2BHsc%2B7An8SA2YU%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Generate the image\n",
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"A beautiful sunset over a calm ocean\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "# Get the image URL\n",
    "image_url = response.data[0].url\n",
    "\n",
    "# Display the image in the notebook\n",
    "display(Image(url=image_url))\n",
    "\n",
    "# If you want to save the image locally\n",
    "# import requests\n",
    "# \n",
    "# img_data = requests.get(image_url).content\n",
    "# with open('generated_image.jpg', 'wb') as handler:\n",
    "#     handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41ae40cc-13ae-45d7-a542-c066b805ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new overlay: light_overlay.png\n",
      "Presentation saved successfully as 'output.pptx'\n"
     ]
    }
   ],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.enum.shapes import MSO_SHAPE\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Assuming you have already created the OpenAI client\n",
    "# client = openai.OpenAI(api_key=\"your-api-key\")\n",
    "\n",
    "def generate_and_save_image(client, prompt, output_path):\n",
    "    try:\n",
    "        response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=prompt,\n",
    "            size=\"1024x1024\",\n",
    "            quality=\"standard\",\n",
    "            n=1,\n",
    "        )\n",
    "        image_url = response.data[0].url\n",
    "        \n",
    "        # Download the image\n",
    "        image_response = requests.get(image_url)\n",
    "        image = Image.open(io.BytesIO(image_response.content))\n",
    "        \n",
    "        # Save the image\n",
    "        image.save(output_path)\n",
    "        print(f\"Image saved successfully as '{output_path}'\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating the image: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def create_translucent_overlay(width, height, opacity, is_dark, output_path):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Overlay {output_path} already exists, skipping creation.\")\n",
    "        return\n",
    "\n",
    "    color = (0, 0, 0, opacity) if is_dark else (255, 255, 255, opacity)\n",
    "    image = Image.new('RGBA', (width, height), color)\n",
    "    image.save(output_path)\n",
    "    print(f\"Created new overlay: {output_path}\")\n",
    "\n",
    "def create_slide_with_image(pptx_path, image_path, text, text_color='black'):\n",
    "    # Create a new presentation\n",
    "    prs = Presentation()\n",
    "\n",
    "    # Slide dimensions\n",
    "    slide_width = prs.slide_width\n",
    "    slide_height = prs.slide_height\n",
    "\n",
    "    # Add a blank slide\n",
    "    blank_slide_layout = prs.slide_layouts[6]\n",
    "    slide = prs.slides.add_slide(blank_slide_layout)\n",
    "\n",
    "    try:\n",
    "        # Open the image\n",
    "        with Image.open(image_path) as img:\n",
    "            # Calculate aspect ratios\n",
    "            img_ratio = img.width / img.height\n",
    "            slide_ratio = slide_width / slide_height\n",
    "\n",
    "            if img_ratio > slide_ratio:\n",
    "                # Image is wider, crop the sides\n",
    "                new_width = int(img.height * slide_ratio)\n",
    "                left = (img.width - new_width) // 2\n",
    "                img = img.crop((left, 0, left + new_width, img.height))\n",
    "            else:\n",
    "                # Image is taller, crop the top and bottom\n",
    "                new_height = int(img.width / slide_ratio)\n",
    "                top = (img.height - new_height) // 2\n",
    "                img = img.crop((0, top, img.width, top + new_height))\n",
    "\n",
    "            # Convert dimensions to EMU (English Metric Units)\n",
    "            img_width = int(slide_width)\n",
    "            img_height = int(slide_height)\n",
    "\n",
    "        # Add the image to the slide\n",
    "        slide.shapes.add_picture(image_path, 0, 0, width=img_width, height=img_height)\n",
    "\n",
    "        # Determine overlay color based on text color\n",
    "        is_dark_overlay = text_color.lower() == 'white'\n",
    "        overlay_filename = 'dark_overlay.png' if is_dark_overlay else 'light_overlay.png'\n",
    "        \n",
    "        # Create and add the translucent overlay\n",
    "        create_translucent_overlay(\n",
    "            width=img_width // 12700, \n",
    "            height=img_height // 12700, \n",
    "            opacity=128, \n",
    "            is_dark=is_dark_overlay,\n",
    "            output_path=overlay_filename\n",
    "        )\n",
    "        slide.shapes.add_picture(overlay_filename, 0, 0, width=img_width, height=img_height)\n",
    "\n",
    "        # Add text box over the translucent overlay\n",
    "        txBox = slide.shapes.add_textbox(Inches(1), Inches(1), Inches(8), Inches(1))\n",
    "        tf = txBox.text_frame\n",
    "        p = tf.add_paragraph()\n",
    "        p.text = text\n",
    "        p.font.size = Pt(44)\n",
    "        p.font.color.rgb = RGBColor(255, 255, 255) if text_color.lower() == 'white' else RGBColor(0, 0, 0)\n",
    "\n",
    "        # Save the presentation\n",
    "        prs.save(pptx_path)\n",
    "        print(f\"Presentation saved successfully as '{pptx_path}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating the slide: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"generated_image.png\"\n",
    "output_pptx = \"output.pptx\"\n",
    "slide_text = \"AI-Generated Landscape\"\n",
    "text_color = \"black\"  # \"white\" or \"black\"\n",
    "\n",
    "create_slide_with_image(output_pptx, image_path, slide_text, text_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90bce98-09f7-4aac-a0e1-eddad875291c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Agents (Python)",
   "language": "python",
   "name": "ai_agents_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
